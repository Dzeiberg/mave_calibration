{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from data_processing.main import read_scoreset\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from data_processing.mapping_nbs import mapping_utils\n",
    "from data_processing.mapping_nbs import plotting\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "dataset_name = \"Matreyek_TPMT_VampSeq\"\n",
    "dataset_path = Path(\"/data/dzeiberg/mave_calibration/data/\") / dataset_name\n",
    "assert dataset_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata, gene_info, gnomAD_df, spliceAI_df, clinvar_df = mapping_utils.load_mapping_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreset = read_scoreset(dataset_path / \"scoreset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"author_transcript\" not in scoreset.columns or scoreset.author_transcript.isna().all():\n",
    "    AUTHOR_TRANSCRIPT = gene_info.loc[metadata.loc[dataset_name],'MANE_RefSeq_nuc'].values[0].split(\".\")[0]\n",
    "else:\n",
    "    AUTHOR_TRANSCRIPT = scoreset.author_transcript.iloc[0].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR_TRANSCRIPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add ClinVar annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_hgvs_pro_summaries = mapping_utils.get_clinvar_summaries(clinvar_df,AUTHOR_TRANSCRIPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreset_w_clinvar = pd.merge(scoreset.set_index(\"hgvs_pro\"),clinvar_hgvs_pro_summaries,\n",
    "                            left_index=True,\n",
    "                            right_index=True,\n",
    "                            how=\"left\",\n",
    "                            validate=\"one_to_one\",\n",
    "                            suffixes=(\"\",\"_clinvar\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add gnomAD annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensembl_transcript_stable_ids = mapping_utils.translate_refseq_to_ensembl(AUTHOR_TRANSCRIPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensembl_transcript_stable_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnomAD_info = mapping_utils.gather_gnomAD_info(gnomAD_df,Ensembl_transcript_stable_ids,[AUTHOR_TRANSCRIPT,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreset_processed = pd.merge(scoreset_w_clinvar,gnomAD_info,\n",
    "                                        left_index=True,right_index=True,how=\"left\",validate=\"one_to_one\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreset_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreset_processed.to_csv(dataset_path / \"scoreset_processed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreset_processed = pd.read_csv(dataset_path / \"scoreset_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conflicting_interpretations(r):\n",
    "    \"\"\"\n",
    "    Check if a record has conflicting interpretations\n",
    "    P/LP and B/LB ; P/LP and VUS ; B/LB and VUS ; P/LP and conflicting ; B/LB and conflicting\n",
    "    If data is mapped at the protein level, this could be a result of different RNA substitutions\n",
    "    If data is mapped at the RNA level, this is a true conflict\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r : pd.Series\n",
    "        A record from the ClinVar data frame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if there are conflicting interpretations, False otherwise\n",
    "    \"\"\"\n",
    "    return r.num_p_lp > 0 and r.num_b_lb > 0 or \\\n",
    "            r.num_p_lp > 0 and r.num_VUS > 0 or \\\n",
    "            r.num_b_lb > 0 and r.num_VUS > 0 or \\\n",
    "            r.num_p_lp > 0 and r.num_conflicting > 0 or \\\n",
    "            r.num_b_lb > 0 and r.num_conflicting > 0\n",
    "\n",
    "\n",
    "def is_pathogenic(r):\n",
    "    return r.num_p_lp > 0 and not conflicting_interpretations(r) and r.clinvar_spliceAI_max <= .5\n",
    "\n",
    "def is_benign(r):\n",
    "    return r.num_b_lb > 0 and not conflicting_interpretations(r) and r.clinvar_spliceAI_max <= .5\n",
    "\n",
    "def is_vus(r):\n",
    "    return r.num_VUS > 0\n",
    "\n",
    "def is_conflicting(r):\n",
    "    return r.num_conflicting > 0\n",
    "\n",
    "def is_gnomAD(r):\n",
    "    return r.gnomAD_variants_maxAC_AF > 0 and r.gnomAD_variants_max_spliceAI_score <= .5\n",
    "\n",
    "def is_synonymous(r):\n",
    "    return r.synonymous and r.num_p_lp == 0 and r.clinvar_spliceAI_max <= .5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = {\n",
    "    \"P/LP\" : scoreset_processed[scoreset_processed.apply(lambda r: not r.nonsense and is_pathogenic(r),axis=1)],\n",
    "    \"B/LB\" : scoreset_processed[scoreset_processed.apply(lambda r: not r.nonsense and is_benign(r),axis=1)],\n",
    "    'gnomAD': scoreset_processed[scoreset_processed.apply(lambda r: not r.nonsense and is_gnomAD(r),axis=1)],\n",
    "    'synonymous' : scoreset_processed[scoreset_processed.apply(is_synonymous,axis=1)],\n",
    "}\n",
    "sample_data = {k : v for k,v in sample_data.items() if len(v)}\n",
    "\n",
    "INVERT_SCORES = False\n",
    "if INVERT_SCORES:\n",
    "    for k in sample_data:\n",
    "        sample_data[k] = sample_data[k].assign(score= -sample_data[k].score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_name, sample in sample_data.items():\n",
    "    print(f\"{sample_name}: {sample.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_samples({k : v.score.values for k,v in sample_data.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records([*[dict(sample_name='P/LP',score=score) for score in sample_data['P/LP'].score.values],\n",
    "                            *[dict(sample_name='B/LB',score=score) for score in sample_data['B/LB'].score.values],\n",
    "                            *[dict(sample_name='gnomAD',score=score) for score in sample_data['gnomAD'].score.values],\n",
    "                            *[dict(sample_name='synonymous',score=score) for score in sample_data['synonymous'].score.values]]).to_csv(dataset_path / \"samples.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = joblib.load(dataset_path / \"hgvs_pro.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_hgvs_pro_summaries[clinvar_hgvs_pro_summaries.index.isin(set(old['p_lp'].values) - set(sample_data['P/LP'].hgvs_pro.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_hgvs_pro_summaries[clinvar_hgvs_pro_summaries.index.isin(set(old['b_lb'].values) - set(sample_data['B/LB'].hgvs_pro.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mave-calibration-xCjwkSk6-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
