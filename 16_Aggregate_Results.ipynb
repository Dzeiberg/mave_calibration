{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from main import load_data\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from main import prior_from_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/mnt/i/bio/mave_curation/\")\n",
    "results_dir = Path(\"/mnt/d/mave_calibration/results_08_07_24/\")\n",
    "with open(data_dir / \"dataset_configs.json\") as f:\n",
    "    dataset_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {sample_name : load_data(dataset_id=sample_name,\n",
    "                                data_directory=data_dir) \\\n",
    "        for sample_name in os.listdir(data_dir) if os.path.isdir(data_dir / sample_name) and sample_name in dataset_config}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_result(r_dir):\n",
    "    with open(r_dir / \"result.json\") as f:\n",
    "        result = json.load(f)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oob_indices(result, X):\n",
    "    return np.array(list(set(list(range(X.shape[0]))) - \\\n",
    "                         set(np.concatenate(result[\"bootstrap_indices\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mave_calibration.skew_normal import density_utils\n",
    "def get_lrPlus(S, result,pathogenic_sample_num=0, benign_sample_num=1):\n",
    "    f_P = density_utils.joint_densities(S, result['component_params'], result['weights'][pathogenic_sample_num]).sum(0)\n",
    "    f_B = density_utils.joint_densities(S, result['component_params'], result['weights'][benign_sample_num]).sum(0)\n",
    "    return f_P / f_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_oob(result, X):\n",
    "    oob_indices = get_oob_indices(result, X)\n",
    "    predictions = np.ones(X.shape[0]) * np.nan\n",
    "    oob_obs = X[oob_indices]\n",
    "    predictions[oob_indices] = get_lrPlus(oob_obs, result)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oob_predictions(dataset_name,sample_num=None, return_quantiles=False, return_all=False):\n",
    "    X,S = data[dataset_name][:2]\n",
    "    if sample_num is not None:\n",
    "        x_sample = X[S[:,sample_num]]\n",
    "    else:\n",
    "        x_sample = X\n",
    "    preds = []\n",
    "    for iter_result in results_dir.glob(f\"iter_*/{dataset_name}\"):\n",
    "        result = read_result(iter_result)\n",
    "        preds.append(predict_on_oob(result, x_sample))\n",
    "    P = np.stack(preds)\n",
    "    if return_all:\n",
    "        return P\n",
    "    quantiles = np.nanquantile(P, [0.25, .5, 0.75], axis=0)\n",
    "    if return_quantiles:\n",
    "        return quantiles[1], quantiles[[0,-1],:]\n",
    "    return quantiles[1]\n",
    "\n",
    "def predict(X, dataset_name, return_quantiles=False, return_all=False):\n",
    "    preds = []\n",
    "    for iter_result in results_dir.glob(f\"iter_*/{dataset_name}\"):\n",
    "        if not os.path.isfile(iter_result / \"result.json\"):\n",
    "            continue\n",
    "        result = read_result(iter_result)\n",
    "        preds.append(get_lrPlus(X, result))\n",
    "    P = np.stack(preds)\n",
    "    if return_all:\n",
    "        return P\n",
    "    quantiles = np.nanquantile(P, [0.25, .5, 0.75], axis=0)\n",
    "    if return_quantiles:\n",
    "        return quantiles[1], quantiles[[0,-1],:]\n",
    "    return quantiles[1]\n",
    "\n",
    "def get_priors(dataset_name):\n",
    "    priors = []\n",
    "    for iter_result in results_dir.glob(f\"iter_*/{dataset_name}\"):\n",
    "        if not os.path.isfile(iter_result / \"result.json\"):\n",
    "            continue\n",
    "        result = read_result(iter_result)\n",
    "        priors.append(prior_from_weights(np.array(result['weights'])))\n",
    "    return priors\n",
    "\n",
    "def get_sample_density(X, dataset_name):\n",
    "    densities = []\n",
    "    for iter_result in results_dir.glob(f\"iter_*/{dataset_name}\"):\n",
    "        result = read_result(iter_result)\n",
    "        iter_densities = [density_utils.joint_densities(X, result['component_params'], result['weights'][i]).sum(0) \\\n",
    "                          for i in range(len(result['sample_names']))]\n",
    "        densities.append(iter_densities)\n",
    "    D = np.stack(densities,axis=1)\n",
    "    return D\n",
    "\n",
    "def aggregate_thresholds(dataset_name,return_all=False,qPathogenic=0.5,qBenign=0.5):\n",
    "    pathogenic_thresholds= []\n",
    "    benign_thresholds = []\n",
    "    for iter_result in results_dir.glob(f\"iter_*/{dataset_name}\"):\n",
    "        result = read_result(iter_result)\n",
    "        pathogenic_thresholds.append(result['pathogenic_thresholds'])\n",
    "        benign_thresholds.append(result['benign_thresholds'])\n",
    "    TP = np.stack(pathogenic_thresholds)\n",
    "    TB = np.stack(benign_thresholds)\n",
    "    if return_all:\n",
    "        return TP, TB\n",
    "    return np.nanquantile(TP, qPathogenic,axis=0), np.nanquantile(TB, qBenign,axis=0)\n",
    "\n",
    "def assign_strength(score, dataset_name,):\n",
    "    lrPlus_median, lrPlus_quantiles = predict(score, dataset_name, return_quantiles=True)\n",
    "    pathogenic_thresholds, benign_thresholds = aggregate_thresholds(dataset_name)\n",
    "    evidence = []\n",
    "    for lrP,lrB in zip(lrPlus_quantiles[0], lrPlus_quantiles[1]):\n",
    "        if lrP > pathogenic_thresholds[-1]:\n",
    "            evidence.append(\"PP3_VeryStrong\")\n",
    "        elif lrP > pathogenic_thresholds[-2]:\n",
    "            evidence.append(\"PP3_Strong\")\n",
    "        elif lrP > pathogenic_thresholds[-3]:\n",
    "            evidence.append(\"PP3_Moderate\")\n",
    "        elif lrP > pathogenic_thresholds[-4]:\n",
    "            evidence.append(\"PP3_Supporting\")\n",
    "        elif lrB < benign_thresholds[-1]:\n",
    "            evidence.append(\"BS3_VeryStrong\")\n",
    "        elif lrB < benign_thresholds[-2]:\n",
    "            evidence.append(\"BS3_Strong\")\n",
    "        elif lrB < benign_thresholds[-3]:\n",
    "            evidence.append(\"BS3_Moderate\")\n",
    "        elif lrB < benign_thresholds[-4]:\n",
    "            evidence.append(\"BS3_Supporting\")\n",
    "        else:\n",
    "            evidence.append(\"Intermediate\")\n",
    "    return evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Jia_MSH2_SSM\"\n",
    "\n",
    "STEP = 0.1\n",
    "X = data[dataset_name][0]\n",
    "# rng = np.arange(np.floor(X.min()),np.ceil(X.max()),STEP)\n",
    "xm = X.min()\n",
    "xM = X.max()\n",
    "rng = np.linspace((xm // .05) * .05, (xM // .05) * .05 + 0.05, 25)\n",
    "# rng = np.arange(X.min(),X.max(),STEP)\n",
    "LR = predict(rng, dataset_name, return_all=True)\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(15,5))\n",
    "sns.boxplot(data=LR,ax=ax,palette=sns.color_palette(\"vlag_r\",n_colors=LR.shape[1]))\n",
    "\n",
    "ax.set_yscale('log')\n",
    "_ = ax.set_xticks(ticks=range(len(rng)),labels=list(map(lambda v: f\"{v:.2f}\",rng)),rotation=90)\n",
    "ax.set_xlabel(\"Assay Score\")\n",
    "ax.set_ylabel(r\"$LR^+$\")\n",
    "pathogenic_thresholds, benign_thresholds = aggregate_thresholds(dataset_name)\n",
    "for tP,tB,ls in zip(pathogenic_thresholds, benign_thresholds,[\":\",\"--\",\"-.\",\"-\"]):\n",
    "    ax.axhline(tP,ls=ls,color='r')\n",
    "    ax.axhline(tB,ls=ls,color='b')\n",
    "# ax.set_ylim(benign_thresholds[-1] * 1e-2,pathogenic_thresholds[-1] * 1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathogenic_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mave_calibration.evidence_thresholds import get_tavtigian_constant, pathogenicRulesPosterior, likelyPathogenicRulesPosterior, benignRulesPosterior, likelybenignRulesPosterior\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(63)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tavtigian_constant(.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ True,  True,  True,  True,  True,  True]),\n",
       " array([ True,  True,  True,  True,  True,  True,  True,  True]),\n",
       " array([ True]),\n",
       " array([ True])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = 63\n",
    "prior = .35\n",
    "[np.round(likelyPathogenicRulesPosterior(C,prior,False),3) >= .9,\n",
    " np.round(pathogenicRulesPosterior(C,prior,False),3) >= .99,\n",
    " np.round(benignRulesPosterior(C,prior),3) <= .01,\n",
    " np.round(likelybenignRulesPosterior(C,prior,False),3) <= .1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Samples = data[dataset_name][1].shape[1]\n",
    "fig,ax = plt.subplots(N_Samples,1,figsize=(10,3*N_Samples),sharex=True,sharey=True)\n",
    "X,S,sample_names = data[dataset_name]\n",
    "rng = np.linspace(X.min(),X.max(),1000)\n",
    "palette = sns.color_palette(\"pastel\", N_Samples)\n",
    "palette_3 = sns.color_palette(\"dark\", N_Samples)\n",
    "palette_2 = sns.color_palette(\"bright\", N_Samples)\n",
    "D = get_sample_density(rng, dataset_name)\n",
    "sample_name_map = dict(p_lp=\"P/LP\", b_lb=\"B/LB\", gnomad=\"gnomAD\", vus=\"VUS\", synonymous=\"Synonymous\",nonsynonymous=\"Nonsynonymous\")\n",
    "for i in range(N_Samples):\n",
    "    sns.histplot(X[S[:,i]],ax=ax[i],stat='density',color=palette[i],label=f\"{sample_name_map[sample_names[i]]} (n={S[:,i].sum():,d})\")\n",
    "    ax[i].plot(rng, D[i].mean(0),color=palette_3[i],)\n",
    "    q = np.nanquantile(D[i], [0.025, .975], axis=0)\n",
    "    ax[i].fill_between(rng, q[0], q[1], alpha=.5, color=palette_2[i])\n",
    "    ax[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set = {k : predict(X[S[:,i]],dataset_name) for i,k in enumerate(sample_names)}\n",
    "obs = load_data(dataset_id=dataset_name,data_directory=data_dir,return_dict=True)\n",
    "prediction_set['vus'] = predict(obs['vus'],dataset_name)\n",
    "\n",
    "sns.violinplot(prediction_set,\n",
    "               orient='h',log_scale=True, bw_adjust=.5, inner='point',palette=sns.color_palette(\"pastel\", len(prediction_set)))\n",
    "\n",
    "plt.xlabel(r\"$LR^+$\")\n",
    "pathogenic_thresholds, benign_thresholds = aggregate_thresholds(dataset_name)\n",
    "for tP,tB,ls in zip(pathogenic_thresholds, benign_thresholds,[\":\",\"--\",\"-.\",\"-\"]):\n",
    "    plt.axvline(tP,ls=ls,color='r',alpha=.5)\n",
    "    plt.axvline(tB,ls=ls,color='b',alpha=.5)\n",
    "plt.gca().invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(obs['vus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postThreshold = .99\n",
    "prior = .35\n",
    "postThreshold / (1 - postThreshold) * (1 - prior) / prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mave-calibration-EHbbm_E7-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
